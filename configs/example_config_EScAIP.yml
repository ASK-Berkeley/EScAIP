model:
  name: src.EfficientlyScaledAttentionInteratomicPotential

  # Global Configs
  activation: gelu                        # activation function in MLPs, all supported ["squared_relu", "gelu", "leaky_relu", "relu", "smelu", "star_relu"]
  direct_force: true                      # direct force or gradient force [Note: gradient force is only supported with "math" attention kernel]
  hidden_size: 128                        # hidden size of the model, devisable by 2 and num_heads
  regress_forces: true                    # whether to predict forces or not
  use_fp16_backbone: false                # whether to use fp16 for the backbone or not


  # Molecular Graph Configs
  avg_num_nodes: 40                       # average number of atoms in a molecule (energy prediction)
  enforce_max_neighbors_strictly: true    # radius graph construction
  distance_function: gaussian             # distance function for edge distance features, all supported ["gaussian", "sigmoid", "linearsigmoid", "silu"]
  max_neighbors: 30                       # radius graph construction: maximum number of neighbors for each atom
  max_num_elements: 90                    # maximum number of elements in the dataset
  max_num_nodes_per_batch: 60             # used for padding, each batch will be padded to this size * batch_size
  max_radius: 6.0                         # radius graph construction: maximum radius for each atom
  otf_graph: true                         # whether to use on-the-fly graph construction or not
  use_pbc: true                           # whether to use periodic boundary conditions or not


  # Graph Neural Networks Configs
  atom_embedding_size: 128                # size of the atom embeddings
  atten_name: memory_efficient            # attention layer name, all supported ["memory_efficient", "math", "flash", "xformers"]
  atten_num_heads: 8                      # number of attention heads
  edge_distance_embedding_size: 512       # size of the edge distance embeddings
  edge_distance_expansion_size: 600       # size of the edge distance expansion
  node_direction_embedding_size: 64       # size of the node direction embeddings
  node_direction_expansion_size: 10       # size of the node direction expansion
  num_layers: 6                           # number of layers in the model
  output_hidden_layer_multiplier: 2       # hidden layer multiplier for the output FFN
  readout_hidden_layer_multiplier: 2      # hidden layer multiplier for the readout FFN
  ffn_hidden_layer_multiplier: 2          # hidden layer multiplier for the FFNs in the main blocks


  # Regularization Configs
  atten_dropout: 0.05                     # dropout rate for the attention layers
  mlp_dropout: 0.05                       # dropout rate for the MLPs
  normalization: rmsnorm                  # normalization layer, all supported ["rmsnorm", "layernorm", "skip"]
  stochastic_depth_prob: 0.0              # stochastic depth probability
